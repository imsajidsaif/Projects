{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd26363b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
    "class Model_Implementation():\n",
    "    def Model(self,data_in_form_of_dataframe,model_name):\n",
    "        data=data_in_form_of_dataframe\n",
    "        data.target.value_counts().plot(kind='bar')# ploting barchart to check target values.\n",
    "        data.target.value_counts()\n",
    "        data.columns\n",
    "        data=shuffle(data)\n",
    "        data=data.reset_index().drop(['index'],1)\n",
    "        counter_object=CountVectorizer()# text conversion into vector form by using CountVectorizer\n",
    "        tfidf_object=TfidfVectorizer()  #text conversion into vector form by using TfidfVectorizer\n",
    "        def remove_x_char_from_data(data_in_form_of_dataframe):# removing 'x' from dataset\n",
    "            data=data_in_form_of_dataframe\n",
    "            for i in range(len(data)):\n",
    "                data.merged_data[i]=data.merged_data[i].replace('x','')\n",
    "                data.merge_data_2[i]=data.merge_data_2[i].replace('x','')\n",
    "                return data\n",
    "        data=remove_x_char_from_data(data)\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tf_train_data = pd.concat([data['merged_data'], data['merge_data_2']])# concate merged data(City,address,passcode)\n",
    "        #merged_data merged in the form of (City + Address + passcode(zipcode))\n",
    "        # merge_data_2 and merged_data having similar and non similar data,but both are merged in (City + address +passcode)\n",
    "        trained_tf_idf_transformer = tfidf_vectorizer.fit_transform(tf_train_data)\n",
    "        Vectorized_transform_Data_of_merged_data = tfidf_vectorizer.transform(data['merged_data'])\n",
    "        Vectorized_transform_Data_of_merge_data_2 = tfidf_vectorizer.transform(data['merge_data_2'])\n",
    "        X= hstack([Vectorized_transform_Data_of_merged_data,Vectorized_transform_Data_of_merge_data_2])\n",
    "        Y = data['target'].values\n",
    "        seed = 123\n",
    "        np.random.seed(seed)\n",
    "        x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=.25,random_state=seed)\n",
    "        model=model_name\n",
    "        model.fit(x_train, y_train)\n",
    "        pred_tfidf=model.predict(x_test)\n",
    "        return round(accuracy_score(y_test,pred_tfidf),2)\n",
    "\n",
    "\n",
    "data=pd.read_excel(\"data_completed_4.xlsx\")\n",
    "\n",
    "dataclass_obj=Model_Implementation()\n",
    "naive_object=MultinomialNB()\n",
    "svc_model=SVC()\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "random_forest=RandomForestClassifier()\n",
    "naive_accuracy=dataclass_obj.Model(data,naive_object)\n",
    "svc_model_acc=dataclass_obj.Model(data,svc_model)\n",
    "decision_tree_acc=dataclass_obj.Model(data,decision_tree)\n",
    "\n",
    "random_forest_acc=dataclass_obj.Model(data,random_forest)\n",
    "print(\"Model_accuracies are :\",naive_accuracy,svc_model_acc,decision_tree_acc,random_forest_acc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0284e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ffa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclass_obj=Model_Implementation()\n",
    "Decision_tree_obj=DecisionTreeClassifier()\n",
    "naive_object=MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf694b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclass_obj.Model(data,naive_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b391a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436690a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaddf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6acabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400ad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8ee14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd37c9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c91668",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_3=pd.read_excel(\"data_completed_4.xlsx\")\n",
    "training_3\n",
    "training_3.target.value_counts().plot(kind='bar')\n",
    "training_3.target.value_counts()\n",
    "training_3.columns\n",
    "training_3['address'] = training_3.apply(lambda x: ''.join(x['merged_data'].lower() + ' ' + str(x['merge_data_2'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb338f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef577484",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_3[training_3.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_3=shuffle(training_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_3=training_3.reset_index().drop(['index'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a48f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_=CountVectorizer()\n",
    "tfidf_=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c42c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a5545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f6cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorizer#CountVectorizer\n",
    "# seed = 123\n",
    "# np.random.seed(seed)\n",
    "# x_train,x_test,y_train,y_test=train_test_split(training_data_count,target,test_size=.25,random_state=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66d96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83aa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd4bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=training_3[[\"merged_data\",\"merge_data_2\"]]\n",
    "# seed = 123\n",
    "# np.random.seed(seed)\n",
    "# x_train2,x_test2,y_train2,y_test2=train_test_split(train,target,test_size=.25,random_state=seed)\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train = vectorizer.fit_transform(x_train2)\n",
    "# X_test= vectorizer.fit_transform(x_test2)\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# transformer1 = MaxAbsScaler().fit(X_train)\n",
    "# X_train_data_tfidf = transformer1.transform(X_train)\n",
    "# X_test_data_tfidf = transformer2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ce007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfddc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=training_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182f841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ad8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.merged_data[i]=df.merged_data[i].replace('x','')\n",
    "    df.merge_data_2[i]=df.merge_data_2[i].replace('x','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84aabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.columns[:-3]].drop(['Unnamed: 0'],1).to_csv(\"x_cleaned_data.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb11ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "# raw_data = pd.DataFrame(*raw_data, columns = ['id', 'is_identical', 'q1', 'q2'])\n",
    "tf_train_data = pd.concat([df['merged_data'], df['merge_data_2']])\n",
    "trained_tf_idf_transformer = tfidf_vectorizer.fit_transform(tf_train_data)\n",
    "data1= tfidf_vectorizer.transform(df['merged_data'])\n",
    "data2 = tfidf_vectorizer.transform(df['merge_data_2'])\n",
    "data_for_model = df[['tf_idf_q1', 'tf_idf_q2', 'target']]\n",
    "X= hstack([data1,data2])\n",
    "Y = df['target'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af58af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9bf07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14fa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58c7d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=.25,random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "pred_tfidf=model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6649ba17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b28a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98533886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nv_model=MultinomialNB()\n",
    "nv_model.fit(x_train, y_train)\n",
    "pred_tfidf=nv_model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svc_model=SVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "pred_tfidf=svc_model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "svc_model=DecisionTreeClassifier()\n",
    "svc_model.fit(x_train, y_train)\n",
    "pred_tfidf=svc_model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29495d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model=SVC()\n",
    "svc_model.fit(x_train, y_train)\n",
    "pred_tfidf=svc_model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "svc_model=DecisionTreeClassifier()\n",
    "svc_model.fit(x_train, y_train)\n",
    "pred_tfidf=svc_model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898e9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tfidf=model.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.sparse import coo_matrix, hstack \n",
    "# tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "# tfidf_vectorizer_2=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "\n",
    "# data1=tfidf_vectorizer.fit_transform(training_3['merged_data'].values)\n",
    "# data2=tfidf_vectorizer_2.fit_transform(training_3['merge_data_2'].values)\n",
    "\n",
    "# # data1 = tfidf_vectorizer.transform(training_3['merged_data'].values)\n",
    "# # data2 = tfidf_vectorizer_2.transform(training_3['merge_data_2'].values)\n",
    "\n",
    "# X= hstack([data1,data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1e7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af905345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ad397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "# X_count = vectorizer.fit_transform(training_3[\"address\"])\n",
    "\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# transformer = MaxAbsScaler().fit(X_count)\n",
    "# training_data_count = transformer.transform(X_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target=training_3.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8904e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbaef99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21874a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier,GradientBoostingClassifier,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=LogisticRegression()\n",
    "model2=RandomForestClassifier()\n",
    "\n",
    "model4=ExtraTreesClassifier()\n",
    "model5=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85794ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x_train,y_train)\n",
    "pred_tfidf=model2.predict(x_test)\n",
    "accuracy_score(y_test,pred_tfidf) #..........................TFIDF ACCURACY.........................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9241aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce83070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5017b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking overvfitting and underfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bfd82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed1828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test2,pred_tfidf))\n",
    "print(classification_report(y_test2,pred_tfidf))\n",
    "print(accuracy_score(y_test2,pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00c0fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,pred_count))\n",
    "print(classification_report(y_test,pred_count))\n",
    "print(accuracy_score(y_test,pred_count))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acdde49f",
   "metadata": {},
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# X_ = vectorizer.fit_transform(['xxxxxxxxxxxxxxxja business unit lohja 8150 xxxxxxxxxxxxxxxJA BUSINESS UNIT LOHJA 8150'])\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# transformer_ = MaxAbsScaler().fit(X_)\n",
    "# training_data_tfidf_ = transformer_.transform(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f30b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def predict_car(s,train=training_3,model=log_obj_TFIDF):\n",
    "#     pred=model.predict(training_data_tfidf_)\n",
    "#     print(train.target[pred_tfidf[0]])\n",
    "#     return train.target[pred_tfidf[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22646cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78437a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, learning_curve, validation_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = RandomForestClassifier(n_estimators=100, bootstrap=True, random_state=0)\n",
    "clf_1.fit(x_train2, y_train2)\n",
    "# Number of folds for cross validation\n",
    "num_folds = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(ticks, train_scores, test_scores):\n",
    "    train_scores_mean = -1 * np.mean(train_scores, axis=1)\n",
    "    train_scores_std = -1 * np.std(train_scores, axis=1)\n",
    "    test_scores_mean = -1 * np.mean(test_scores, axis=1)\n",
    "    test_scores_std = -1 * np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.fill_between(ticks, \n",
    "                     train_scores_mean - train_scores_std, \n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"b\")\n",
    "    plt.fill_between(ticks, \n",
    "                     test_scores_mean - test_scores_std, \n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.plot(ticks, train_scores_mean, 'b-', label='Training score')\n",
    "    plt.plot(ticks, test_scores_mean, 'r-', label='Test score')\n",
    "    plt.legend(fancybox=True, facecolor='w')\n",
    "\n",
    "    return plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e6d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fa9c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_validation_curve(clf, X, y, param_name, param_range, scoring='roc_auc'):\n",
    "    plt.xkcd()\n",
    "    ax = plot_curve(param_range, *validation_curve(clf, X, y, cv=num_folds, \n",
    "                                                   scoring=scoring, \n",
    "                                                   param_name=param_name, \n",
    "                                                   param_range=param_range, n_jobs=-1))\n",
    "    ax.set_title('')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlim(2,12)\n",
    "    ax.set_ylim(-0.97, -0.83)\n",
    "    ax.set_ylabel('Error')\n",
    "    ax.set_xlabel('Model complexity')\n",
    "    ax.text(9, -0.94, 'Overfitting', fontsize=22)\n",
    "    ax.text(3, -0.94, 'Underfitting', fontsize=22)\n",
    "    ax.axvline(7, ls='--')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef73672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_validation_curve(clf_1, x_train2, y_train2, param_name='max_depth', param_range=range(2,13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a54965",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod=RandomForestClassifier()\n",
    "mod.fit(x_train2,y_train2)\n",
    "pred=mod.predict(x_test2)\n",
    "accuracy_score(y_test2,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88006cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing=pd.read_excel(\"combined_data.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98c28c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing['merged']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testing)):\n",
    "    testing['merged'][i]=str(testing.Address[i])+\" \"+str(testing.City[i])+\" \"+str(testing['Post Code'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['merged_2']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9fb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testing)):\n",
    "    testing['merged_2'][i]=str(testing.Address[i])+\" \"+str(testing.City[i])+\" \"+str(testing['Post Code'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde0d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.merged_2=shuffle(testing.merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['address'] = testing.apply(lambda x: ''.join(x['merged'].lower() + ' ' + str(x['merged_2'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc945710",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=testing[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433b8e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe9e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"random_forest_model.pkl\",'rb') as file:\n",
    "    model=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bef12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(training_3[\"address\"])\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# transformer = MaxAbsScaler().fit(X)\n",
    "# training_data_tfidf = transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f7be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_ = TfidfVectorizer()\n",
    "X_count_ = vectorizer_.fit_transform(test[\"address\"])\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "transformer_ = MaxAbsScaler().fit(X_count_)\n",
    "training_data_count_ = transformer_.transform(X_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec303c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c77e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=model.predict(training_data_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4574d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
