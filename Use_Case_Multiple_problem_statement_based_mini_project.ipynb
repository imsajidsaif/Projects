{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting filename & sheet name of a input Excel & return a dat frame\n",
    "def generate_data(file, sheet_name):\n",
    "    data = pd.read_excel(file, sheet_name = sheet_name)\n",
    "    data = data.fillna('')\n",
    "    df = pd.DataFrame()\n",
    "    df['Description'] = data['S:Description']\n",
    "    return df\n",
    "# Combining all the sheets Test Steps & returning a combined data frame\n",
    "import pandas as pd\n",
    "final_df = pd.DataFrame()\n",
    "file = 'Pre execution test scripts (2).xlsx'\n",
    "for sheet_name in pd.ExcelFile(file).sheet_names:\n",
    "    final_df = pd.concat([final_df, generate_data(file, sheet_name)])\n",
    "\n",
    "def multiple_problem_Statement(data_df):\n",
    "    data.Description[0]\n",
    "    data.Statement[0]\n",
    "    from nltk import sent_tokenize\n",
    "    for i in range(len(data)):\n",
    "        data.iloc[i,0]=sent_tokenize(data.iloc[i,0])\n",
    "    wanted_keys=['Launch','Click','Select','Launch','Verify','Expand','Enter','add']\n",
    "    from collections import Counter\n",
    "    a=[]\n",
    "    for i in range(len(data.Description)):\n",
    "        for j in data.Description[i]:\n",
    "           a+=j.split()\n",
    "    counts =( Counter(a))\n",
    "    counts=dict(counts)\n",
    "    for key,val in counts.items():\n",
    "        if val>50:\n",
    "            print(key,\":\",val)\n",
    "    data.Description[0][0]\n",
    "    new_l=[]\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data.Description[i])):\n",
    "            if \"Note:\" in data.Description[i][j] or \"Role:\" in data.Description[i][j]:\n",
    "                new_l.append(data.Description[i][:j])\n",
    "            else:\n",
    "                new_l.append(data.Description[i])\n",
    "    for i in range(len(data.Description)):\n",
    "        data.Description[i]=data.Description[i][0]\n",
    "    non_eng_words=[]\n",
    "    def my_cleaner(text):\n",
    "        from nltk.tokenize import sent_tokenize\n",
    "        list_for_clean_text=[]\n",
    "\n",
    "\n",
    "        Extra_token=[\"NA\",\"Good\",\"https\",'dear',\"http\" ,'hi','team',\"www.\",'hello','regard','regards','please','Dear', 'Hi','Team','Hello','Thank','Regard', 'Please','Thank You','Thank you','thank you']\n",
    "        import re\n",
    "        text=\" \".join(text.split())\n",
    "        for i in text.split():\n",
    "            if i in Extra_token or \"http\" in i or \"https\" in i or \"www.\" in i or \".com\" in i:\n",
    "                i=\"\"\n",
    "            else:\n",
    "                list_for_clean_text.append(i)\n",
    "        text =\" \".join(list_for_clean_text).replace(\"?\",\".\")\n",
    "        text =  re.sub(r\"\\\\t|\\\\n|\\\\r|#|<br>|$|\",\"\",text)\n",
    "        text =  re.sub(r\"\\t|\\n|\\r\",\" \",text)\n",
    "        text = re.sub(\"doesn´t\", \"does not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"isn’t\", \"is not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"What’s\", \"What is\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"wasn’t\", \"was not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"won’t\", \"will not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"hasn’t\", \"has not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"haven’t\", \"have not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"hadn’t\", \"had not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"I’m\", \"I am\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"don’t\", \"do not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"weren’t\", \"were not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"doesn’t\", \"does not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(i|I)’ve\", \"I have\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(H|h)e’s\", \"He has\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(S|h)e’s\", \"She has\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(I|i)t’s\", \"It has\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"You’ve\", \"You have\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(W|w)’ve\", \"We have\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(T|t)hey’ve\", \"They have\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(i|I)’d\", \"I had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(H|h)e’d\", \"He had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(S|h)e’d\", \"She had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(I|i)t’d\", \"It had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"You’d\", \"You had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(W|w)’d\", \"We had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(T|t)hey’d\", \"They had\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"can’t\", \"can not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"wouldn’t\", \"would not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"couldn’t\", \"could not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"mustn’t\", \"could not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"shan’t\", \"shall not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"shouldn’t\", \"should not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(i|I)’ll\", \"I will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(H|h)e’ll\", \"He will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(S|h)e’ll\", \"She will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(I|i)t’ll\", \"It will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"You’ll\", \"You will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(W|w)’ll\", \"We will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"we’ll\", \"We will\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"(T|t)hey’ll\", \"They will\", text, flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"(s|S)erviceA\", \"service\", text, flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"(w|W)orkspace\", \"workspace\", text, flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"it's\",\"it is\",text,flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"’s\",\" is\",text,flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"(L|l)et’s\",\"let us\",text,flags=re.IGNORECASE)\n",
    "        text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "        text =  re.sub(\"Toll\",\" Toll\",text,flags=re.IGNORECASE) \n",
    "        text =  re.sub(\"should’ve\",\"should have\",text,flags=re.IGNORECASE) \n",
    "        text = re.sub(\"\\'ve\", \" have \", text)\n",
    "        text = re.sub(\"can't\", \"can not\", text)\n",
    "        text = re.sub(\"n't\", \" not \", text)\n",
    "        text = re.sub(\"n`t\", \" not \", text)\n",
    "        text = re.sub(\"didn’t\", \"did not\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"\\'re\", \" are \", text)\n",
    "        text = re.sub(\"\\'d\", \" would \", text)\n",
    "        text = re.sub(\"\\'ll\", \" will \", text)\n",
    "        text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"it´s\", \"it has\", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(\"doesn t\", \" does not \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"(e|E) signatures\", \" esignatures \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"https\", \" https\", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"Feeditem\", \"Feed item\", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"scenariosforService\", \"scenarios for Service\", text, flags=re.IGNORECASE)    \n",
    "        #text = re.sub(\"(r|R)ef\", \" Refrence \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"Modified\", \" Modified \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"KONGMACAUKOREATAIWANJAPAN\", \" KONG MACAU KOREA TAIWAN JAPAN \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"THAILANDHONG\", \" THAILAND HONG \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"Published\", \" Published \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"Modified\", \" Modified \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub(\"@(k|K)nowledge\", \" @knowledge \", text, flags=re.IGNORECASE)    \n",
    "        text = re.sub('CID', ' ', text)\n",
    "        text=text.replace(\"N/A\",\" \")\n",
    "        text=text.replace(\"/\",\" \")\n",
    "        text=text.replace(\"<<<\",\" \")\n",
    "        text=text.replace(\"‘\",\"\")\n",
    "        text=text.replace(\"’\",\"\")\n",
    "        text=text.replace(\"“\",\"\")\n",
    "        text=text.replace(\"”\",\"\")\n",
    "        text=text.replace('\"',\"\")\n",
    "        text=text.replace('„',\"\")\n",
    "        text=text.replace(\"\\xa0\",\" \")\n",
    "        text=text.replace(\"--\",\" \")\n",
    "        text=text.replace(\"-\",\" \")\n",
    "        text=text.replace(\"(\",\"\")\n",
    "        text=text.replace(\")\",\"\")\n",
    "        text=text.replace(\"!\",\".\")\n",
    "        text=text.replace(\"#\",\"\")\n",
    "        text=text.replace(\"$\",\"\")\n",
    "        text=text.replace(\";\",\"\")\n",
    "        text=text.replace(\":\",\" \")\n",
    "        text=text.replace(\"=\",\"\")\n",
    "        text=text.replace(\">>\",\" \")\n",
    "        text=text.replace(\"***\",\" \")\n",
    "        text=text.replace(\"~\",\" \")\n",
    "        text=text.replace(\"+\",\" \")\n",
    "        text=text.replace(\",\",\" \")\n",
    "        text=text.replace(\"....\",\" \")\n",
    "        text=text.replace(\". .\",\" \")\n",
    "        text=text.replace(\"> >\",\" \")\n",
    "        text=text.replace(\">\",\" \")\n",
    "        text=text.replace(\"•\",\"\")\n",
    "        text=text.replace(\"[\",\" \")\n",
    "        text=text.replace(\"]\",\"\")\n",
    "        text=text.replace(\"<\",\"\")\n",
    "        text=text.replace(\"–\",\" \")\n",
    "        text=text.replace(\"<hr\",\"\")\n",
    "        text=text.replace('|',\"\")\n",
    "        text=text.replace('..',\"\")\n",
    "        text=text.replace('…',\" \")\n",
    "        text=text.replace(\"*\",\"\")\n",
    "        text=text.replace(\"_\",\" \")\n",
    "        text=text.replace(\"®\",\" \")\n",
    "\n",
    "        text=text.replace(\"morning\",\"\")\n",
    "        text=\" \".join(text.split())\n",
    "        list_of_sentences=sent_tokenize(text)\n",
    "        for sent in list_of_sentences:\n",
    "            if sent.isascii():\n",
    "                text=text\n",
    "            else:\n",
    "                non_eng_words.append(sent)\n",
    "        return text\n",
    "    data['Description_1']=data.Description.apply(lambda a:my_cleaner(a))\n",
    "    new=[]\n",
    "    for i in data.Description_1:\n",
    "        new.append(sent_tokenize(i))\n",
    "    count=0\n",
    "    stmnt=[]\n",
    "    descrip=[]\n",
    "    for i in new:\n",
    "        for j in i:\n",
    "            words = j.split()\n",
    "            counts = {}\n",
    "            for word in words:\n",
    "                if word not in counts:\n",
    "                    counts[word] = 0\n",
    "                counts[word] += 1\n",
    "            for ll in wanted_keys:\n",
    "                for key,val in counts.items():\n",
    "                    if key==ll:\n",
    "                        if val>1:\n",
    "                            print(key,\":\",val)\n",
    "                            stmnt.append(\"Multiple\")\n",
    "                            descrip.append(i)\n",
    "                        else:\n",
    "                            stmnt.append(\"Single\")\n",
    "                            descrip.append(i)\n",
    "    up_df=pd.DataFrame({\"Description\":descrip,\"Statement\":stmnt})\n",
    "    for i in range(len(up_df)):\n",
    "        up_df.Description[i]=up_df.Description[i][0]\n",
    "    up_df.to_csv(\"multiple_statemnt_prob.csv\",index=False)\n",
    "    return up_df\n",
    "import pandas as pd\n",
    "data=pd.read_excel('Processed_Pre_Execution_Test_Scripts.xlsx')\n",
    "multiple_problem_Statement(data)# function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
